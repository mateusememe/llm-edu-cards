# üöÄ Guia R√°pido de Instala√ß√£o e Uso

## Sistema de Cards Educacionais com LLMs

### ‚ö° In√≠cio R√°pido (5 minutos)

#### 1. Pr√©-requisitos

Antes de come√ßar, certifique-se de ter:

- ‚úÖ Python 3.8 ou superior instalado
- ‚úÖ Conex√£o com internet
- ‚úÖ Conta no HuggingFace (gratuita)

#### 2. Obter Token do HuggingFace

1. Acesse: https://huggingface.co/join
2. Crie sua conta (gratuita)
3. V√° em: Settings ‚Üí Access Tokens
4. Clique em "New token"
5. D√™ um nome (ex: "llm-cards")
6. Selecione permiss√£o "Read"
7. Copie o token gerado

**Formato do token:** `hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx`

---

## üì¶ Instala√ß√£o

### Op√ß√£o 1: Instala√ß√£o B√°sica

```bash
# Clone o reposit√≥rio
git clone https://github.com/mateusememe/llm-edu-cards.git
cd llm-cards-educacionais

# Instale as depend√™ncias
pip install -r requirements.txt

# Execute a aplica√ß√£o
streamlit run app.py
```

### Op√ß√£o 2: Ambiente Virtual (Recomendado)

```bash
# Clone o reposit√≥rio
git clone https://github.com/mateusememe/llm-edu-cards.git
cd llm-cards-educacionais

# Crie ambiente virtual
python -m venv venv

# Ative o ambiente virtual
# No Windows:
venv\Scripts\activate
# No Linux/Mac:
source venv/bin/activate

# Instale as depend√™ncias
pip install -r requirements.txt

# Execute a aplica√ß√£o
streamlit run app.py
```

### Op√ß√£o 3: Google Colab

```python
# Execute no Google Colab
!pip install streamlit langchain langchain-community huggingface-hub

# Baixe o arquivo app.py
!wget https://raw.githubusercontent.com/mateusememe/llm-edu-cards/main/app.py

# Execute com tunnel
!streamlit run app.py & npx localtunnel --port 8501
```

---

## üñ•Ô∏è Uso da Interface

### 1. Primeira Execu√ß√£o

Ap√≥s executar `streamlit run app.py`, o navegador abrir√° automaticamente em:
```
http://localhost:8501
```

### 2. Configura√ß√£o Inicial

**Na barra lateral esquerda:**

1. **Insira seu Token:**
   - Cole o token do HuggingFace
   - Clique fora do campo para salvar

2. **(Opcional) Ajuste Par√¢metros:**
   - Expanda "Par√¢metros Avan√ßados"
   - Ajuste Temperature (0.0 - 1.0)
   - Ajuste Max Tokens (100 - 1000)

### 3. Gerando Cards

**Na √°rea principal:**

1. **Digite um tema:**
   ```
   Ex: Redes Neurais Convolucionais
   ```

2. **Clique em "Gerar Cards"**
   - Aguarde o processamento (2-5 segundos)

3. **Visualize os resultados:**
   - Resumo explicativo aparece primeiro
   - 3 subtemas relacionados aparecem em cards

4. **Explore subtemas:**
   - Clique em "üîç Explorar" em qualquer card
   - Sistema gera novos cards para aquele subtema

### 4. Comparando Modelos

Para comparar modelos no mesmo tema:

1. Gere cards com o primeiro modelo
2. Mude o modelo na sidebar
3. Digite o mesmo tema novamente
4. Compare os resultados no hist√≥rico

---

## üí° Exemplos Pr√°ticos

### Exemplo 1: Explorando IA

```
1. Digite: "Intelig√™ncia Artificial"
2. Clique em "Gerar Cards"
3. Explore subtema: "Machine Learning"
4. Explore subtema: "Redes Neurais"
5. Continue explorando...
```

### Exemplo 2: Estudando Matem√°tica

```
1. Digite: "√Ålgebra Linear"
2. Clique em "Gerar Cards"
3. Explore subtema: "Matrizes e Determinantes"
4. Use um modelo diferente
5. Compare as explica√ß√µes
```

### Exemplo 3: Temas Interdisciplinares

```
1. Digite: "Computa√ß√£o Qu√¢ntica"
2. Clique em "Gerar Cards"
3. Observe os subtemas gerados
4. Explore progressivamente
```

---

## ‚öôÔ∏è Ajuste de Par√¢metros

### Temperature

**O que faz:** Controla a "criatividade" do modelo

```
0.0 - 0.3: Respostas muito precisas e determin√≠sticas
          Recomendado para: Conte√∫do t√©cnico, matem√°tica

0.3 - 0.7: Equil√≠brio entre precis√£o e criatividade
          Recomendado para: Conte√∫do educacional geral

0.7 - 1.0: Respostas mais criativas e variadas
          Recomendado para: Brainstorming, ideias
```

**Recomenda√ß√£o:** Mantenha entre 0.3 - 0.4 para uso educacional

### Max Tokens

**O que faz:** Limita o tamanho da resposta

```
100 - 300:  Respostas curtas e diretas
300 - 600:  Respostas m√©dias (recomendado)
600 - 1000: Respostas detalhadas
```

**Recomenda√ß√£o:** Mantenha em 800 para equil√≠brio

---

## üêõ Solu√ß√£o de Problemas

### Erro: "Invalid API token"

**Causa:** Token do HuggingFace incorreto

**Solu√ß√£o:**
1. Verifique se copiou o token completo
2. Gere um novo token no HuggingFace
3. Cole novamente na interface

### Erro: "Model loading failed"

**Causa:** Modelo n√£o dispon√≠vel ou sobrecarga

**Solu√ß√£o:**

1. Tente outro modelo
2. Aguarde alguns minutos
3. Verifique sua conex√£o com internet

### Interface n√£o carrega

**Causa:** Porta 8501 ocupada

**Solu√ß√£o:**

```bash
# Use outra porta
streamlit run app.py --server.port 8502
```

### Respostas muito lentas

**Causa:** Lat√™ncia da API do HuggingFace

**Solu√ß√£o:**
1. Aguarde em hor√°rios de pico
2. Reduza max_tokens

### Erro de depend√™ncias

**Causa:** Vers√µes incompat√≠veis

**Solu√ß√£o:**
```bash
# Desinstale tudo
pip uninstall -y streamlit langchain langchain-community

# Reinstale
pip install -r requirements.txt
```

---

## üì± Uso Avan√ßado

### 1. Executar Testes Comparativos

```bash
# Execute o script de testes
python test_comparative.py

# Siga as instru√ß√µes
# Digite seu token quando solicitado
```

**O script ir√°:**
- Testar todos os 3 modelos
- Usar 5 temas pr√©-definidos
- Gerar relat√≥rio comparativo
- Exportar resultados em JSON

### 2. Personalizar Prompts

Edite o arquivo `app.py`:

```python
# Localize a fun√ß√£o gerar_resumo()
# Modifique o template:

template = """Seu prompt personalizado aqui...
{question}
"""
```

### 3. Adicionar Novos Modelos

```python
# No app.py, adicione em MODELS:

MODELS = {
    # ... modelos existentes ...
    "Seu-Modelo": {
        "repo_id": "org/modelo-nome",
        "temperature": 0.4,
        "max_tokens": 800,
        "description": "Descri√ß√£o do modelo"
    }
}
```

---

## üìä Interpretando Resultados

### Qualidade do Resumo

**Bom resumo cont√©m:**

- ‚úÖ Defini√ß√£o clara do conceito
- ‚úÖ Contexto e import√¢ncia
- ‚úÖ Exemplos ou aplica√ß√µes
- ‚úÖ Linguagem acess√≠vel

**Evite resumos que:**

- ‚ùå S√£o muito vagos ou gen√©ricos
- ‚ùå Cont√™m informa√ß√µes incorretas
- ‚ùå S√£o dif√≠ceis de entender
- ‚ùå Fogem do tema principal

### Qualidade dos Subtemas

**Bons subtemas s√£o:**

- ‚úÖ Espec√≠ficos e relevantes
- ‚úÖ Relacionados ao tema principal
- ‚úÖ Explor√°veis (geram novos cards)
- ‚úÖ Educacionalmente √∫teis

---

## üéØ Dicas de Uso

### Para Estudantes

1. **Comece Amplo, Aprofunde Gradualmente**
   ```
   "Machine Learning" ‚Üí "Redes Neurais" ‚Üí "CNNs"
   ```

2. **Compare Modelos**
   - Teste o mesmo tema em modelos diferentes
   - Observe diferentes abordagens explicativas

3. **Use o Hist√≥rico**
   - Revise cards anteriores
   - Crie um "mapa mental" do tema

4. **Ajuste para seu Estilo**
   - Temperature mais baixa = mais objetivo
   - Temperature mais alta = mais exemplos

### Para Professores

1. **Prepara√ß√£o de Aulas**
   - Gere outlines de t√≥picos
   - Identifique conceitos relacionados

2. **Avalia√ß√£o de Modelos**
   - Compare qualidade educacional
   - Identifique melhores abordagens

3. **Cria√ß√£o de Exerc√≠cios**
   - Use subtemas como base
   - Explore conex√µes entre conceitos

---

## üîí Seguran√ßa e Privacidade

### Sobre seu Token

- ‚úÖ O token N√ÉO √© armazenado permanentemente
- ‚úÖ V√°lido apenas durante a sess√£o
- ‚úÖ N√£o √© compartilhado com terceiros
- ‚ö†Ô∏è N√£o commite o token no Git

### Dados Gerados

- ‚úÖ Cards ficam apenas na sua sess√£o
- ‚úÖ Nada √© salvo no servidor
- ‚úÖ Hist√≥rico √© local
- ‚úÖ Privacidade total

---

## üìö Recursos Adicionais

### Documenta√ß√£o

- **README.md**: Vis√£o geral do projeto
- **DOCUMENTACAO.md**: Documenta√ß√£o t√©cnica completa
- **test_comparative.py**: C√≥digo de testes

### Links √öteis

- **HuggingFace:** https://huggingface.co/
- **Streamlit Docs:** https://docs.streamlit.io/
- **LangChain Docs:** https://python.langchain.com/
- **PPGCC-UNESP:** https://www.ibilce.unesp.br/#!/pos-graduacao/

### Comunidade

- üìß Suporte: Via canais da disciplina
- üí¨ Discuss√µes: GitHub Issues
- üêõ Bugs: GitHub Issues
- üí° Sugest√µes: GitHub Discussions

---

## ‚úÖ Checklist de Uso

### Antes de Come√ßar

- [ ] Python instalado (3.8+)
- [ ] Depend√™ncias instaladas
- [ ] Token HuggingFace obtido
- [ ] Aplica√ß√£o executando

### Primeiro Uso

- [ ] Token inserido na sidebar
- [ ] Modelo selecionado
- [ ] Primeiro tema testado
- [ ] Cards gerados com sucesso

## üí™ Pr√≥ximos Passos

### Ap√≥s Instala√ß√£o

1. ‚úÖ Teste com 3-5 temas diferentes
2. ‚úÖ Compare os 3 modelos
3. ‚úÖ Leia a documenta√ß√£o completa

---

## üôã Perguntas Frequentes

### P: Preciso pagar pelo token do HuggingFace?
**R:** N√£o! O tier gratuito √© suficiente para este projeto.

### P: Posso usar offline?
**R:** N√£o, os modelos rodam na nuvem do HuggingFace.

### P: Quanto tempo demora cada consulta?
**R:** Entre 2-5 segundos, dependendo do modelo e carga do servidor.

### P: Posso adicionar mais modelos?
**R:** Sim! Qualquer modelo do HuggingFace compat√≠vel com LangChain.

### P: Como exporto meus cards?
**R:** Atualmente, use print/screenshot. Export em PDF √© melhoria futura.

### P: Funciona em qual navegador?
**R:** Chrome, Firefox, Safari, Edge - qualquer navegador moderno.

---

*Sistema desenvolvido para a disciplina de Aprendizado Profundo - PPGCC/UNESP*
